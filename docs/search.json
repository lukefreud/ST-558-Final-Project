[
  {
    "objectID": "Modeling.html",
    "href": "Modeling.html",
    "title": "ST558FinalModeling",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(caret)\n\nWarning: package 'caret' was built under R version 4.3.3\n\n\nLoading required package: lattice\n\nAttaching package: 'caret'\n\nThe following object is masked from 'package:purrr':\n\n    lift\n\nlibrary(forcats)\nlibrary(scales)\n\n\nAttaching package: 'scales'\n\nThe following object is masked from 'package:purrr':\n\n    discard\n\nThe following object is masked from 'package:readr':\n\n    col_factor\n\nlibrary(ModelMetrics)\n\nWarning: package 'ModelMetrics' was built under R version 4.3.3\n\n\n\nAttaching package: 'ModelMetrics'\n\nThe following objects are masked from 'package:caret':\n\n    confusionMatrix, precision, recall, sensitivity, specificity\n\nThe following object is masked from 'package:base':\n\n    kappa\n\n\nIn this file, we will attempt to find the best statistical model to predict the presence/absence of diabetes in a subject. We will first split the data into a training set and testing set. The training set will be the set of data that the models are trained on. The testing set will be the set of data the models will make predictions about. We will compare the different models with respect to accuracy in predicting the response variable in the test set. The three different types of models we will fit are logistic regression models, classification tree models, and random forest models. In each logistic regression model, we will use a different set of predictors, and compare the sets of predictors with each other to find the most accurate model. In the classification tree and random forest models, we will use the set of predictors that performed best in logistic regression and then use cross validation to find the best tuning parameters to use in the model.\n\n\n\ndata &lt;- read_csv(\"diabetes_binary_health_indicators_BRFSS2015.csv\")\n\nRows: 253680 Columns: 22\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (22): Diabetes_binary, HighBP, HighChol, CholCheck, BMI, Smoker, Stroke,...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ndata &lt;- data |&gt;\n  mutate(Diabetes_binary = as.factor(Diabetes_binary),\n         HighBP = as.factor(HighBP),\n         HighChol = as.factor(HighChol),\n         Smoker = as.factor(Smoker),\n         Age = as.factor(Age),\n         Education = as.factor(Education),\n         PhysActivity = as.factor(PhysActivity),\n         Fruits = as.factor(Fruits),\n         Veggies = as.factor(Veggies)\n  )\ndata &lt;- data |&gt;\n  select(where(is.factor), BMI) |&gt;\n  mutate(Diabetes_binary = fct_recode(Diabetes_binary,\"NoDiabetes\" = \"0\",\n                        \"Diabetes\" = \"1\"),\n         HighBP = fct_recode(HighBP, \"No\" = \"0\",\n                             \"Yes\" = \"1\"),\n         HighChol = fct_recode(HighChol, \"No\" = \"0\",\n                               \"Yes\" = \"1\"),\n         Smoker = fct_recode(Smoker, \"No\" = \"0\",\n                               \"Yes\" = \"1\"),\n         PhysActivity = fct_recode(PhysActivity, \"No\" = \"0\",\n                               \"Yes\" = \"1\"),\n         Fruits = fct_recode(Fruits, \"No\" = \"0\",\n                             \"Yes\" = \"1\"),\n         Veggies = fct_recode(Veggies, \"No\" = \"0\",\n                              \"Yes\" = \"1\"),\n         Age = fct_recode(Age, \n                          \"18-24\" = \"1\",\n                          \"25-29\" = \"2\",\n                          \"30-34\" = \"3\",\n                          \"35-39\" = \"4\",\n                          \"40-44\" = \"5\",\n                          \"45-49\" = \"6\",\n                          \"50-54\" = \"7\",\n                          \"55-59\" = \"8\",\n                          \"60-64\" = \"9\",\n                          \"65-69\" = \"10\",\n                          \"70-74\" = \"11\",\n                          \"75-79\" = \"12\",\n                          \"80+\" = \"13\"),\n         Education = fct_recode(Education,\n                                \"Noschool\" = \"1\",\n                                \"Grades 1-8\" = \"2\",\n                                \"Grades 9-11\" = \"3\",\n                                \"High School Graduate\" = \"4\",\n                                \"College 1-3 Years\" = \"5\",\n                                \"College Graduate\" = \"6\"))\n\n\n\n\nHere, we will split the data into a training set and a testing set. We will put 70% of the data set into the training set and 30% of the data into the testing set.\n\n# Reproducibility\nset.seed(98)\n#indices to split on\ntrain &lt;- sample(1:nrow(data), size = nrow(data)*0.7)\ntest &lt;- setdiff(1:nrow(data), train)\n#subset\nDiabetes_Train &lt;- data[train, ]\nDiabetes_Test &lt;- data[test, ]\n\n\n\n\nIn our models the metric we will use to compare models is Log Loss. Log Loss is a metric that is used to evaluate how well probabilistic classifiers perform. This metric is sometimes more effective than accuracy because it takes into account how uncertain predictions are. For example, if a prediction from a model is very close between selecting diabetes and not selecting diabetes (say it’s 52% likely the subject has diabetes and 48% likely they don’t from the model), then if that prediction is incorrect it is penalized less than a predictions that is almost certain one way or the other (say it’s 90% likely the subject has diabetes and 10% likely they don’t from the model) and is wrong. The lower the value of Log Loss, the better the model is. Accuracy does not have that capability, and only determines whether or not the model correctly predicted the observation. Therefore, we will be using log loss to compare our models.\n\n\n\n\n\nA logistic regression model is a supervised learning algorithm that is used for a binary response variable. The algorithm models the log-odds of an event happening by transforming the linear combination of predictors into a probability between 0 and 1. We are using it in this case because we have a response variable that has only 2 categories (the subject either has diabetes or they don’t have diabetes). One limitation of logistic regression is that there is an assumption of linearity between the predictors and the response variable.\n\n\n\n\ntrctrl &lt;- trainControl(method = \"repeatedcv\", number = 5, classProbs = TRUE, summaryFunction = mnLogLoss)\nLogistic_Model_1 &lt;- train(Diabetes_binary ~ HighBP + HighChol + Smoker + Education + BMI + Veggies + Fruits, data = Diabetes_Train, \n                 method = \"glm\",\n                 family = \"binomial\",\n                 trControl=trctrl,\n                 metric = \"logLoss\",\n                 preProcess = c(\"center\", \"scale\"))\nLogistic_Model_1\n\nGeneralized Linear Model \n\n177576 samples\n     7 predictor\n     2 classes: 'NoDiabetes', 'Diabetes' \n\nPre-processing: centered (11), scaled (11) \nResampling: Cross-Validated (5 fold, repeated 1 times) \nSummary of sample sizes: 142060, 142060, 142061, 142061, 142062 \nResampling results:\n\n  logLoss \n  0.346822\n\nsummary(Logistic_Model_1)\n\n\nCall:\nNULL\n\nCoefficients:\n                                 Estimate Std. Error  z value Pr(&gt;|z|)    \n(Intercept)                     -2.186700   0.009103 -240.219  &lt; 2e-16 ***\nHighBPYes                        0.593975   0.008184   72.579  &lt; 2e-16 ***\nHighCholYes                      0.397270   0.007679   51.735  &lt; 2e-16 ***\nSmokerYes                        0.069448   0.007397    9.388  &lt; 2e-16 ***\n`EducationGrades 1-8`            0.002513   0.029156    0.086  0.93130    \n`EducationGrades 9-11`          -0.056082   0.043503   -1.289  0.19734    \n`EducationHigh School Graduate` -0.238047   0.098356   -2.420  0.01551 *  \n`EducationCollege 1-3 Years`    -0.296166   0.101854   -2.908  0.00364 ** \n`EducationCollege Graduate`     -0.459235   0.112582   -4.079 4.52e-05 ***\nBMI                              0.405199   0.006566   61.716  &lt; 2e-16 ***\nVeggiesYes                      -0.064392   0.007092   -9.079  &lt; 2e-16 ***\nFruitsYes                       -0.003795   0.007487   -0.507  0.61227    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 143865  on 177575  degrees of freedom\nResidual deviance: 123143  on 177564  degrees of freedom\nAIC: 123167\n\nNumber of Fisher Scoring iterations: 5\n\n\nAs we can see from the output, our logLoss for this model is .3468. Looking at the summary, we see that the fruits variable is insignificant. For the next model, we will take this variable out and insert the exercise binary variable.\n\n\n\n\nLogistic_Model_2 &lt;-train(Diabetes_binary ~ HighBP + HighChol + Smoker + Education + BMI + Veggies + PhysActivity, data = Diabetes_Train, \n                 method = \"glm\",\n                 family = \"binomial\",\n                 trControl=trctrl,\n                 metric = \"logLoss\",\n                 preProcess = c(\"center\", \"scale\"))\nLogistic_Model_2\n\nGeneralized Linear Model \n\n177576 samples\n     7 predictor\n     2 classes: 'NoDiabetes', 'Diabetes' \n\nPre-processing: centered (11), scaled (11) \nResampling: Cross-Validated (5 fold, repeated 1 times) \nSummary of sample sizes: 142060, 142061, 142061, 142061, 142061 \nResampling results:\n\n  logLoss  \n  0.3457345\n\nsummary(Logistic_Model_2)\n\n\nCall:\nNULL\n\nCoefficients:\n                                 Estimate Std. Error  z value Pr(&gt;|z|)    \n(Intercept)                     -2.192460   0.009130 -240.126  &lt; 2e-16 ***\nHighBPYes                        0.586452   0.008197   71.547  &lt; 2e-16 ***\nHighCholYes                      0.393838   0.007689   51.223  &lt; 2e-16 ***\nSmokerYes                        0.064005   0.007402    8.647  &lt; 2e-16 ***\n`EducationGrades 1-8`            0.004459   0.029114    0.153 0.878266    \n`EducationGrades 9-11`          -0.052997   0.043439   -1.220 0.222443    \n`EducationHigh School Graduate` -0.223105   0.098210   -2.272 0.023103 *  \n`EducationCollege 1-3 Years`    -0.272105   0.101708   -2.675 0.007465 ** \n`EducationCollege Graduate`     -0.420063   0.112431   -3.736 0.000187 ***\nBMI                              0.390809   0.006580   59.398  &lt; 2e-16 ***\nVeggiesYes                      -0.049447   0.006945   -7.120 1.08e-12 ***\nPhysActivityYes                 -0.134462   0.006882  -19.538  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 143865  on 177575  degrees of freedom\nResidual deviance: 122768  on 177564  degrees of freedom\nAIC: 122792\n\nNumber of Fisher Scoring iterations: 5\n\n\nThe logLoss for this model is .3457, which is slightly lower than the .3468 from the previous model, indicating this model is slightly better. In the summary, we see that all of the variables are significant to the model, so we will not remove any of these predictors and will add age as another predictor.\n\n\n\n\nLogistic_Model_3 &lt;-train(Diabetes_binary ~ HighBP + HighChol + Smoker + Education + BMI + Veggies + PhysActivity + Age, data = Diabetes_Train, \n                 method = \"glm\",\n                 family = \"binomial\",\n                 trControl=trctrl,\n                 metric = \"logLoss\",\n                 preProcess = c(\"center\", \"scale\"))\nLogistic_Model_3\n\nGeneralized Linear Model \n\n177576 samples\n     8 predictor\n     2 classes: 'NoDiabetes', 'Diabetes' \n\nPre-processing: centered (23), scaled (23) \nResampling: Cross-Validated (5 fold, repeated 1 times) \nSummary of sample sizes: 142062, 142061, 142061, 142060, 142060 \nResampling results:\n\n  logLoss  \n  0.3384155\n\n\nIn this model with age added as a predictor, we see that the logLoss is .3384. This is lower than the last two models, so this third model is the best in terms of logLoss. Therefore, we will use this model for our prediction of the test set of data.\n\n\n\n\n\n\nClassification tree models are a form of predictive modeling where the predictor space is split up into different regions. These models are used for classifying which group the response variable is in. There are different predictions within each region in the predictor space. In each of these regions, the prediction made is the most prevalent class of the response variable. One advantage of classification tree models is that they can account for nonlinear trends in data.\n\nClass_Tree_Model &lt;- train(Diabetes_binary ~ HighBP + HighChol + Smoker + Education + BMI + Veggies + PhysActivity + Age, data = Diabetes_Train, \n                 method = \"rpart\",\n                 trControl=trctrl,\n                 metric = \"logLoss\",\n                 preProcess = c(\"center\", \"scale\"),\n                 tuneGrid = expand.grid(cp = seq(0,0.01, by=0.001)))\nClass_Tree_Model\n\nCART \n\n177576 samples\n     8 predictor\n     2 classes: 'NoDiabetes', 'Diabetes' \n\nPre-processing: centered (23), scaled (23) \nResampling: Cross-Validated (5 fold, repeated 1 times) \nSummary of sample sizes: 142060, 142061, 142061, 142062, 142060 \nResampling results across tuning parameters:\n\n  cp     logLoss  \n  0.000  0.3547694\n  0.001  0.3695144\n  0.002  0.3961269\n  0.003  0.4050796\n  0.004  0.4050796\n  0.005  0.4050796\n  0.006  0.4050796\n  0.007  0.4050796\n  0.008  0.4050796\n  0.009  0.4050796\n  0.010  0.4050796\n\nlogLoss was used to select the optimal model using the smallest value.\nThe final value used for the model was cp = 0.\n\n\nIn order to minimize logLoss, the best model was with the tuning parameter cp = 0. Therefore, this is the model we will use in our predictions of the test set. We can see the logLoss of this model in the output above.\n\n\n\n\n\n\nRandom forest models are a type of regression/classification algorithm. In random forest models, the data is first broken down into random subsets (bootstrap samples). After this, multiple trees are created for each bootstrap sample, and each tree has a different set of predictors within it that are randomly selected. Each of these trees make predictions for the bootstrap samples, and then these predictions are averaged to determine the final predictions of each sample. Some reasons that random forest models are implemented is they are typically good for prediction and they don’t allow 1-2 predictors to overpower the model.\n\ntrctrlrf &lt;- trainControl(method = \"repeatedcv\", number = 3, classProbs = TRUE, summaryFunction = mnLogLoss)\nRandom_Forest_Model &lt;- train(Diabetes_binary ~ HighBP + HighChol + Smoker + Education + BMI + Veggies + PhysActivity + Age, data = Diabetes_Train,\n                 method = \"rf\",\n                 trControl=trctrlrf,\n                 metric = \"logLoss\",\n                 preProcess = c(\"center\", \"scale\"),\n                 tuneGrid = data.frame(mtry = 6:8), ntree = 100)\nRandom_Forest_Model\n\nRandom Forest \n\n177576 samples\n     8 predictor\n     2 classes: 'NoDiabetes', 'Diabetes' \n\nPre-processing: centered (23), scaled (23) \nResampling: Cross-Validated (3 fold, repeated 1 times) \nSummary of sample sizes: 118384, 118385, 118383 \nResampling results across tuning parameters:\n\n  mtry  logLoss \n  6     1.964614\n  7     1.895309\n  8     1.818852\n\nlogLoss was used to select the optimal model using the smallest value.\nThe final value used for the model was mtry = 8.\n\n\nFor the random forest model, the tuning parameter that was optimal for the model was mtry = 8. We will use this tuning parameter for the predictions of the test set. We can see the logLoss of this model in the output above.\n\n\n\n\n\n\nFirst, we will use the best logistic regression model fit in order to make predictions on the response variable in the test set of data. We will make a confusion matrix to look at the accuracy of this model.\n\nLR_predictions &lt;- predict(Logistic_Model_3, newdata = Diabetes_Test)\ncaret::confusionMatrix(data = Diabetes_Test$Diabetes_binary, reference = LR_predictions)\n\nConfusion Matrix and Statistics\n\n            Reference\nPrediction   NoDiabetes Diabetes\n  NoDiabetes      64913      717\n  Diabetes         9696      778\n                                          \n               Accuracy : 0.8632          \n                 95% CI : (0.8607, 0.8656)\n    No Information Rate : 0.9804          \n    P-Value [Acc &gt; NIR] : 1               \n                                          \n                  Kappa : 0.099           \n                                          \n Mcnemar's Test P-Value : &lt;2e-16          \n                                          \n            Sensitivity : 0.87004         \n            Specificity : 0.52040         \n         Pos Pred Value : 0.98908         \n         Neg Pred Value : 0.07428         \n             Prevalence : 0.98036         \n         Detection Rate : 0.85295         \n   Detection Prevalence : 0.86237         \n      Balanced Accuracy : 0.69522         \n                                          \n       'Positive' Class : NoDiabetes      \n                                          \n\n\nThe accuracy of the best logistic regression model was 86.32%. Next, we will see how well the classification tree model performs in predicting the presence/absence of diabetes in the test set.\n\n\n\n\nCT_predictions &lt;- predict(Class_Tree_Model, newdata = Diabetes_Test)\ncaret::confusionMatrix(data = Diabetes_Test$Diabetes_binary, reference = CT_predictions)\n\nConfusion Matrix and Statistics\n\n            Reference\nPrediction   NoDiabetes Diabetes\n  NoDiabetes      63788     1842\n  Diabetes         9087     1387\n                                          \n               Accuracy : 0.8564          \n                 95% CI : (0.8539, 0.8589)\n    No Information Rate : 0.9576          \n    P-Value [Acc &gt; NIR] : 1               \n                                          \n                  Kappa : 0.1471          \n                                          \n Mcnemar's Test P-Value : &lt;2e-16          \n                                          \n            Sensitivity : 0.8753          \n            Specificity : 0.4295          \n         Pos Pred Value : 0.9719          \n         Neg Pred Value : 0.1324          \n             Prevalence : 0.9576          \n         Detection Rate : 0.8382          \n   Detection Prevalence : 0.8624          \n      Balanced Accuracy : 0.6524          \n                                          \n       'Positive' Class : NoDiabetes      \n                                          \n\n\nThe accuracy of the classification tree model was 85.64%. This is slightly lower than the accuracy for the logistic regression model was. Lastly, we will see how accurate the random forest model is in predicting the response variable in the test data.\n\n\n\n\nRF_predictions &lt;- predict(Random_Forest_Model, newdata = Diabetes_Test)\ncaret::confusionMatrix(data = Diabetes_Test$Diabetes_binary, reference = RF_predictions)\n\nConfusion Matrix and Statistics\n\n            Reference\nPrediction   NoDiabetes Diabetes\n  NoDiabetes      64463     1167\n  Diabetes         9322     1152\n                                          \n               Accuracy : 0.8622          \n                 95% CI : (0.8597, 0.8646)\n    No Information Rate : 0.9695          \n    P-Value [Acc &gt; NIR] : 1               \n                                          \n                  Kappa : 0.137           \n                                          \n Mcnemar's Test P-Value : &lt;2e-16          \n                                          \n            Sensitivity : 0.8737          \n            Specificity : 0.4968          \n         Pos Pred Value : 0.9822          \n         Neg Pred Value : 0.1100          \n             Prevalence : 0.9695          \n         Detection Rate : 0.8470          \n   Detection Prevalence : 0.8624          \n      Balanced Accuracy : 0.6852          \n                                          \n       'Positive' Class : NoDiabetes      \n                                          \n\n\nThe accuracy of the random forest model in predicting the absence/presence of diabetes in the test set was 86.17%. This accuracy was higher than the accuracy from the classification tree model, but lower than the accuracy from the logistic regression model.\n\n\n\n\nOverall, the best model in terms of accuracy in the predicting of the test set was the logistic regression model. However, the accuracy from this model was 86.32%, which is lower than the No Information Rate of 96.96%. Therefore, saying every subject in the testing set does not have diabetes would actually have more accuracy than these models. Therefore, we would probably need to look into ways to fine tune these models more or add to them before using them."
  },
  {
    "objectID": "Modeling.html#reading-in-and-shaping-data",
    "href": "Modeling.html#reading-in-and-shaping-data",
    "title": "ST558FinalModeling",
    "section": "",
    "text": "data &lt;- read_csv(\"diabetes_binary_health_indicators_BRFSS2015.csv\")\n\nRows: 253680 Columns: 22\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (22): Diabetes_binary, HighBP, HighChol, CholCheck, BMI, Smoker, Stroke,...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ndata &lt;- data |&gt;\n  mutate(Diabetes_binary = as.factor(Diabetes_binary),\n         HighBP = as.factor(HighBP),\n         HighChol = as.factor(HighChol),\n         Smoker = as.factor(Smoker),\n         Age = as.factor(Age),\n         Education = as.factor(Education),\n         PhysActivity = as.factor(PhysActivity),\n         Fruits = as.factor(Fruits),\n         Veggies = as.factor(Veggies)\n  )\ndata &lt;- data |&gt;\n  select(where(is.factor), BMI) |&gt;\n  mutate(Diabetes_binary = fct_recode(Diabetes_binary,\"NoDiabetes\" = \"0\",\n                        \"Diabetes\" = \"1\"),\n         HighBP = fct_recode(HighBP, \"No\" = \"0\",\n                             \"Yes\" = \"1\"),\n         HighChol = fct_recode(HighChol, \"No\" = \"0\",\n                               \"Yes\" = \"1\"),\n         Smoker = fct_recode(Smoker, \"No\" = \"0\",\n                               \"Yes\" = \"1\"),\n         PhysActivity = fct_recode(PhysActivity, \"No\" = \"0\",\n                               \"Yes\" = \"1\"),\n         Fruits = fct_recode(Fruits, \"No\" = \"0\",\n                             \"Yes\" = \"1\"),\n         Veggies = fct_recode(Veggies, \"No\" = \"0\",\n                              \"Yes\" = \"1\"),\n         Age = fct_recode(Age, \n                          \"18-24\" = \"1\",\n                          \"25-29\" = \"2\",\n                          \"30-34\" = \"3\",\n                          \"35-39\" = \"4\",\n                          \"40-44\" = \"5\",\n                          \"45-49\" = \"6\",\n                          \"50-54\" = \"7\",\n                          \"55-59\" = \"8\",\n                          \"60-64\" = \"9\",\n                          \"65-69\" = \"10\",\n                          \"70-74\" = \"11\",\n                          \"75-79\" = \"12\",\n                          \"80+\" = \"13\"),\n         Education = fct_recode(Education,\n                                \"Noschool\" = \"1\",\n                                \"Grades 1-8\" = \"2\",\n                                \"Grades 9-11\" = \"3\",\n                                \"High School Graduate\" = \"4\",\n                                \"College 1-3 Years\" = \"5\",\n                                \"College Graduate\" = \"6\"))"
  },
  {
    "objectID": "Modeling.html#splitting-data",
    "href": "Modeling.html#splitting-data",
    "title": "ST558FinalModeling",
    "section": "",
    "text": "Here, we will split the data into a training set and a testing set. We will put 70% of the data set into the training set and 30% of the data into the testing set.\n\n# Reproducibility\nset.seed(98)\n#indices to split on\ntrain &lt;- sample(1:nrow(data), size = nrow(data)*0.7)\ntest &lt;- setdiff(1:nrow(data), train)\n#subset\nDiabetes_Train &lt;- data[train, ]\nDiabetes_Test &lt;- data[test, ]"
  },
  {
    "objectID": "Modeling.html#describing-log-loss",
    "href": "Modeling.html#describing-log-loss",
    "title": "ST558FinalModeling",
    "section": "",
    "text": "In our models the metric we will use to compare models is Log Loss. Log Loss is a metric that is used to evaluate how well probabilistic classifiers perform. This metric is sometimes more effective than accuracy because it takes into account how uncertain predictions are. For example, if a prediction from a model is very close between selecting diabetes and not selecting diabetes (say it’s 52% likely the subject has diabetes and 48% likely they don’t from the model), then if that prediction is incorrect it is penalized less than a predictions that is almost certain one way or the other (say it’s 90% likely the subject has diabetes and 10% likely they don’t from the model) and is wrong. The lower the value of Log Loss, the better the model is. Accuracy does not have that capability, and only determines whether or not the model correctly predicted the observation. Therefore, we will be using log loss to compare our models."
  },
  {
    "objectID": "Modeling.html#logistic-regression-model",
    "href": "Modeling.html#logistic-regression-model",
    "title": "ST558FinalModeling",
    "section": "",
    "text": "A logistic regression model is a supervised learning algorithm that is used for a binary response variable. The algorithm models the log-odds of an event happening by transforming the linear combination of predictors into a probability between 0 and 1. We are using it in this case because we have a response variable that has only 2 categories (the subject either has diabetes or they don’t have diabetes). One limitation of logistic regression is that there is an assumption of linearity between the predictors and the response variable.\n\n\n\n\ntrctrl &lt;- trainControl(method = \"repeatedcv\", number = 5, classProbs = TRUE, summaryFunction = mnLogLoss)\nLogistic_Model_1 &lt;- train(Diabetes_binary ~ HighBP + HighChol + Smoker + Education + BMI + Veggies + Fruits, data = Diabetes_Train, \n                 method = \"glm\",\n                 family = \"binomial\",\n                 trControl=trctrl,\n                 metric = \"logLoss\",\n                 preProcess = c(\"center\", \"scale\"))\nLogistic_Model_1\n\nGeneralized Linear Model \n\n177576 samples\n     7 predictor\n     2 classes: 'NoDiabetes', 'Diabetes' \n\nPre-processing: centered (11), scaled (11) \nResampling: Cross-Validated (5 fold, repeated 1 times) \nSummary of sample sizes: 142060, 142060, 142061, 142061, 142062 \nResampling results:\n\n  logLoss \n  0.346822\n\nsummary(Logistic_Model_1)\n\n\nCall:\nNULL\n\nCoefficients:\n                                 Estimate Std. Error  z value Pr(&gt;|z|)    \n(Intercept)                     -2.186700   0.009103 -240.219  &lt; 2e-16 ***\nHighBPYes                        0.593975   0.008184   72.579  &lt; 2e-16 ***\nHighCholYes                      0.397270   0.007679   51.735  &lt; 2e-16 ***\nSmokerYes                        0.069448   0.007397    9.388  &lt; 2e-16 ***\n`EducationGrades 1-8`            0.002513   0.029156    0.086  0.93130    \n`EducationGrades 9-11`          -0.056082   0.043503   -1.289  0.19734    \n`EducationHigh School Graduate` -0.238047   0.098356   -2.420  0.01551 *  \n`EducationCollege 1-3 Years`    -0.296166   0.101854   -2.908  0.00364 ** \n`EducationCollege Graduate`     -0.459235   0.112582   -4.079 4.52e-05 ***\nBMI                              0.405199   0.006566   61.716  &lt; 2e-16 ***\nVeggiesYes                      -0.064392   0.007092   -9.079  &lt; 2e-16 ***\nFruitsYes                       -0.003795   0.007487   -0.507  0.61227    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 143865  on 177575  degrees of freedom\nResidual deviance: 123143  on 177564  degrees of freedom\nAIC: 123167\n\nNumber of Fisher Scoring iterations: 5\n\n\nAs we can see from the output, our logLoss for this model is .3468. Looking at the summary, we see that the fruits variable is insignificant. For the next model, we will take this variable out and insert the exercise binary variable.\n\n\n\n\nLogistic_Model_2 &lt;-train(Diabetes_binary ~ HighBP + HighChol + Smoker + Education + BMI + Veggies + PhysActivity, data = Diabetes_Train, \n                 method = \"glm\",\n                 family = \"binomial\",\n                 trControl=trctrl,\n                 metric = \"logLoss\",\n                 preProcess = c(\"center\", \"scale\"))\nLogistic_Model_2\n\nGeneralized Linear Model \n\n177576 samples\n     7 predictor\n     2 classes: 'NoDiabetes', 'Diabetes' \n\nPre-processing: centered (11), scaled (11) \nResampling: Cross-Validated (5 fold, repeated 1 times) \nSummary of sample sizes: 142060, 142061, 142061, 142061, 142061 \nResampling results:\n\n  logLoss  \n  0.3457345\n\nsummary(Logistic_Model_2)\n\n\nCall:\nNULL\n\nCoefficients:\n                                 Estimate Std. Error  z value Pr(&gt;|z|)    \n(Intercept)                     -2.192460   0.009130 -240.126  &lt; 2e-16 ***\nHighBPYes                        0.586452   0.008197   71.547  &lt; 2e-16 ***\nHighCholYes                      0.393838   0.007689   51.223  &lt; 2e-16 ***\nSmokerYes                        0.064005   0.007402    8.647  &lt; 2e-16 ***\n`EducationGrades 1-8`            0.004459   0.029114    0.153 0.878266    \n`EducationGrades 9-11`          -0.052997   0.043439   -1.220 0.222443    \n`EducationHigh School Graduate` -0.223105   0.098210   -2.272 0.023103 *  \n`EducationCollege 1-3 Years`    -0.272105   0.101708   -2.675 0.007465 ** \n`EducationCollege Graduate`     -0.420063   0.112431   -3.736 0.000187 ***\nBMI                              0.390809   0.006580   59.398  &lt; 2e-16 ***\nVeggiesYes                      -0.049447   0.006945   -7.120 1.08e-12 ***\nPhysActivityYes                 -0.134462   0.006882  -19.538  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 143865  on 177575  degrees of freedom\nResidual deviance: 122768  on 177564  degrees of freedom\nAIC: 122792\n\nNumber of Fisher Scoring iterations: 5\n\n\nThe logLoss for this model is .3457, which is slightly lower than the .3468 from the previous model, indicating this model is slightly better. In the summary, we see that all of the variables are significant to the model, so we will not remove any of these predictors and will add age as another predictor.\n\n\n\n\nLogistic_Model_3 &lt;-train(Diabetes_binary ~ HighBP + HighChol + Smoker + Education + BMI + Veggies + PhysActivity + Age, data = Diabetes_Train, \n                 method = \"glm\",\n                 family = \"binomial\",\n                 trControl=trctrl,\n                 metric = \"logLoss\",\n                 preProcess = c(\"center\", \"scale\"))\nLogistic_Model_3\n\nGeneralized Linear Model \n\n177576 samples\n     8 predictor\n     2 classes: 'NoDiabetes', 'Diabetes' \n\nPre-processing: centered (23), scaled (23) \nResampling: Cross-Validated (5 fold, repeated 1 times) \nSummary of sample sizes: 142062, 142061, 142061, 142060, 142060 \nResampling results:\n\n  logLoss  \n  0.3384155\n\n\nIn this model with age added as a predictor, we see that the logLoss is .3384. This is lower than the last two models, so this third model is the best in terms of logLoss. Therefore, we will use this model for our prediction of the test set of data."
  },
  {
    "objectID": "Modeling.html#classification-tree-models",
    "href": "Modeling.html#classification-tree-models",
    "title": "ST558FinalModeling",
    "section": "",
    "text": "Classification tree models are a form of predictive modeling where the predictor space is split up into different regions. These models are used for classifying which group the response variable is in. There are different predictions within each region in the predictor space. In each of these regions, the prediction made is the most prevalent class of the response variable. One advantage of classification tree models is that they can account for nonlinear trends in data.\n\nClass_Tree_Model &lt;- train(Diabetes_binary ~ HighBP + HighChol + Smoker + Education + BMI + Veggies + PhysActivity + Age, data = Diabetes_Train, \n                 method = \"rpart\",\n                 trControl=trctrl,\n                 metric = \"logLoss\",\n                 preProcess = c(\"center\", \"scale\"),\n                 tuneGrid = expand.grid(cp = seq(0,0.01, by=0.001)))\nClass_Tree_Model\n\nCART \n\n177576 samples\n     8 predictor\n     2 classes: 'NoDiabetes', 'Diabetes' \n\nPre-processing: centered (23), scaled (23) \nResampling: Cross-Validated (5 fold, repeated 1 times) \nSummary of sample sizes: 142060, 142061, 142061, 142062, 142060 \nResampling results across tuning parameters:\n\n  cp     logLoss  \n  0.000  0.3547694\n  0.001  0.3695144\n  0.002  0.3961269\n  0.003  0.4050796\n  0.004  0.4050796\n  0.005  0.4050796\n  0.006  0.4050796\n  0.007  0.4050796\n  0.008  0.4050796\n  0.009  0.4050796\n  0.010  0.4050796\n\nlogLoss was used to select the optimal model using the smallest value.\nThe final value used for the model was cp = 0.\n\n\nIn order to minimize logLoss, the best model was with the tuning parameter cp = 0. Therefore, this is the model we will use in our predictions of the test set. We can see the logLoss of this model in the output above."
  },
  {
    "objectID": "Modeling.html#random-forest-models",
    "href": "Modeling.html#random-forest-models",
    "title": "ST558FinalModeling",
    "section": "",
    "text": "Random forest models are a type of regression/classification algorithm. In random forest models, the data is first broken down into random subsets (bootstrap samples). After this, multiple trees are created for each bootstrap sample, and each tree has a different set of predictors within it that are randomly selected. Each of these trees make predictions for the bootstrap samples, and then these predictions are averaged to determine the final predictions of each sample. Some reasons that random forest models are implemented is they are typically good for prediction and they don’t allow 1-2 predictors to overpower the model.\n\ntrctrlrf &lt;- trainControl(method = \"repeatedcv\", number = 3, classProbs = TRUE, summaryFunction = mnLogLoss)\nRandom_Forest_Model &lt;- train(Diabetes_binary ~ HighBP + HighChol + Smoker + Education + BMI + Veggies + PhysActivity + Age, data = Diabetes_Train,\n                 method = \"rf\",\n                 trControl=trctrlrf,\n                 metric = \"logLoss\",\n                 preProcess = c(\"center\", \"scale\"),\n                 tuneGrid = data.frame(mtry = 6:8), ntree = 100)\nRandom_Forest_Model\n\nRandom Forest \n\n177576 samples\n     8 predictor\n     2 classes: 'NoDiabetes', 'Diabetes' \n\nPre-processing: centered (23), scaled (23) \nResampling: Cross-Validated (3 fold, repeated 1 times) \nSummary of sample sizes: 118384, 118385, 118383 \nResampling results across tuning parameters:\n\n  mtry  logLoss \n  6     1.964614\n  7     1.895309\n  8     1.818852\n\nlogLoss was used to select the optimal model using the smallest value.\nThe final value used for the model was mtry = 8.\n\n\nFor the random forest model, the tuning parameter that was optimal for the model was mtry = 8. We will use this tuning parameter for the predictions of the test set. We can see the logLoss of this model in the output above."
  },
  {
    "objectID": "Modeling.html#predictions-and-final-model-selection",
    "href": "Modeling.html#predictions-and-final-model-selection",
    "title": "ST558FinalModeling",
    "section": "",
    "text": "First, we will use the best logistic regression model fit in order to make predictions on the response variable in the test set of data. We will make a confusion matrix to look at the accuracy of this model.\n\nLR_predictions &lt;- predict(Logistic_Model_3, newdata = Diabetes_Test)\ncaret::confusionMatrix(data = Diabetes_Test$Diabetes_binary, reference = LR_predictions)\n\nConfusion Matrix and Statistics\n\n            Reference\nPrediction   NoDiabetes Diabetes\n  NoDiabetes      64913      717\n  Diabetes         9696      778\n                                          \n               Accuracy : 0.8632          \n                 95% CI : (0.8607, 0.8656)\n    No Information Rate : 0.9804          \n    P-Value [Acc &gt; NIR] : 1               \n                                          \n                  Kappa : 0.099           \n                                          \n Mcnemar's Test P-Value : &lt;2e-16          \n                                          \n            Sensitivity : 0.87004         \n            Specificity : 0.52040         \n         Pos Pred Value : 0.98908         \n         Neg Pred Value : 0.07428         \n             Prevalence : 0.98036         \n         Detection Rate : 0.85295         \n   Detection Prevalence : 0.86237         \n      Balanced Accuracy : 0.69522         \n                                          \n       'Positive' Class : NoDiabetes      \n                                          \n\n\nThe accuracy of the best logistic regression model was 86.32%. Next, we will see how well the classification tree model performs in predicting the presence/absence of diabetes in the test set.\n\n\n\n\nCT_predictions &lt;- predict(Class_Tree_Model, newdata = Diabetes_Test)\ncaret::confusionMatrix(data = Diabetes_Test$Diabetes_binary, reference = CT_predictions)\n\nConfusion Matrix and Statistics\n\n            Reference\nPrediction   NoDiabetes Diabetes\n  NoDiabetes      63788     1842\n  Diabetes         9087     1387\n                                          \n               Accuracy : 0.8564          \n                 95% CI : (0.8539, 0.8589)\n    No Information Rate : 0.9576          \n    P-Value [Acc &gt; NIR] : 1               \n                                          \n                  Kappa : 0.1471          \n                                          \n Mcnemar's Test P-Value : &lt;2e-16          \n                                          \n            Sensitivity : 0.8753          \n            Specificity : 0.4295          \n         Pos Pred Value : 0.9719          \n         Neg Pred Value : 0.1324          \n             Prevalence : 0.9576          \n         Detection Rate : 0.8382          \n   Detection Prevalence : 0.8624          \n      Balanced Accuracy : 0.6524          \n                                          \n       'Positive' Class : NoDiabetes      \n                                          \n\n\nThe accuracy of the classification tree model was 85.64%. This is slightly lower than the accuracy for the logistic regression model was. Lastly, we will see how accurate the random forest model is in predicting the response variable in the test data.\n\n\n\n\nRF_predictions &lt;- predict(Random_Forest_Model, newdata = Diabetes_Test)\ncaret::confusionMatrix(data = Diabetes_Test$Diabetes_binary, reference = RF_predictions)\n\nConfusion Matrix and Statistics\n\n            Reference\nPrediction   NoDiabetes Diabetes\n  NoDiabetes      64463     1167\n  Diabetes         9322     1152\n                                          \n               Accuracy : 0.8622          \n                 95% CI : (0.8597, 0.8646)\n    No Information Rate : 0.9695          \n    P-Value [Acc &gt; NIR] : 1               \n                                          \n                  Kappa : 0.137           \n                                          \n Mcnemar's Test P-Value : &lt;2e-16          \n                                          \n            Sensitivity : 0.8737          \n            Specificity : 0.4968          \n         Pos Pred Value : 0.9822          \n         Neg Pred Value : 0.1100          \n             Prevalence : 0.9695          \n         Detection Rate : 0.8470          \n   Detection Prevalence : 0.8624          \n      Balanced Accuracy : 0.6852          \n                                          \n       'Positive' Class : NoDiabetes      \n                                          \n\n\nThe accuracy of the random forest model in predicting the absence/presence of diabetes in the test set was 86.17%. This accuracy was higher than the accuracy from the classification tree model, but lower than the accuracy from the logistic regression model."
  },
  {
    "objectID": "Modeling.html#overall-best-model-and-discussion-of-results",
    "href": "Modeling.html#overall-best-model-and-discussion-of-results",
    "title": "ST558FinalModeling",
    "section": "",
    "text": "Overall, the best model in terms of accuracy in the predicting of the test set was the logistic regression model. However, the accuracy from this model was 86.32%, which is lower than the No Information Rate of 96.96%. Therefore, saying every subject in the testing set does not have diabetes would actually have more accuracy than these models. Therefore, we would probably need to look into ways to fine tune these models more or add to them before using them."
  },
  {
    "objectID": "EDA.html",
    "href": "EDA.html",
    "title": "Final Project EDA File",
    "section": "",
    "text": "The data we have for this report is from kaggle.com. The data set we are examining is from a health-related telephone survey that is collected annually from the CDC. There are 253,680 observations in the data set we will read in. The response variable that we will be looking at is a binary variable that represents whether or not the subject has diabetes. The goal of this project will be to build different models and compare them as to which model most effectively predicts the presence/absence of diabetes in a subject. We will use one numeric predictor in our models and that is BMI. The other variables we will analyze are some factor variables: Whether or not the subject has high blood pressure, whether or not the subject has high cholesterol, whether or not the subject is a smoker, whether or not the subject does any physical exercise, whether or not the subject consumed fruits/vegetables daily, the age group of the subject, and the highest education level of the subject.\nIn this file, we will do some EDA (Exploratory Data Analysis) on our data set. This is done on data sets to explore some relationships we have between some of the predictors we will use in our models and our response variable. We can use this to get a sense of which variables seem important in predicting whether or not a subject has diabetes. We will try to explore this data set by examining numerical summaries, tables, and graphs of variables given.\nIn general, the primary goal of statistical modeling is to find a combination of predictor variables that are able to most accurately predict future values for a certain response variable. In this process, it also allows you to identify relationships between variables."
  },
  {
    "objectID": "EDA.html#reading-in-the-data",
    "href": "EDA.html#reading-in-the-data",
    "title": "Final Project EDA File",
    "section": "Reading in the Data",
    "text": "Reading in the Data\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nAttaching package: 'scales'\n\n\nThe following object is masked from 'package:purrr':\n\n    discard\n\n\nThe following object is masked from 'package:readr':\n\n    col_factor\n\n\n\ndata &lt;- read_csv(\"diabetes_binary_health_indicators_BRFSS2015.csv\")\n\nRows: 253680 Columns: 22\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (22): Diabetes_binary, HighBP, HighChol, CholCheck, BMI, Smoker, Stroke,...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nhead(data)\n\n# A tibble: 6 × 22\n  Diabetes_binary HighBP HighChol CholCheck   BMI Smoker Stroke\n            &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1               0      1        1         1    40      1      0\n2               0      0        0         0    25      1      0\n3               0      1        1         1    28      0      0\n4               0      1        0         1    27      0      0\n5               0      1        1         1    24      0      0\n6               0      1        1         1    25      1      0\n# ℹ 15 more variables: HeartDiseaseorAttack &lt;dbl&gt;, PhysActivity &lt;dbl&gt;,\n#   Fruits &lt;dbl&gt;, Veggies &lt;dbl&gt;, HvyAlcoholConsump &lt;dbl&gt;, AnyHealthcare &lt;dbl&gt;,\n#   NoDocbcCost &lt;dbl&gt;, GenHlth &lt;dbl&gt;, MentHlth &lt;dbl&gt;, PhysHlth &lt;dbl&gt;,\n#   DiffWalk &lt;dbl&gt;, Sex &lt;dbl&gt;, Age &lt;dbl&gt;, Education &lt;dbl&gt;, Income &lt;dbl&gt;\n\n\nWe will now change some of the variables to factors.\n\ndata &lt;- data |&gt;\n  mutate(Diabetes_binary = as.factor(Diabetes_binary),\n         HighBP = as.factor(HighBP),\n         HighChol = as.factor(HighChol),\n         Smoker = as.factor(Smoker),\n         Age = as.factor(Age),\n         Education = as.factor(Education),\n         PhysActivity = as.factor(PhysActivity),\n         Fruits = as.factor(Fruits),\n         Veggies = as.factor(Veggies)\n  )\nhead(data)\n\n# A tibble: 6 × 22\n  Diabetes_binary HighBP HighChol CholCheck   BMI Smoker Stroke\n  &lt;fct&gt;           &lt;fct&gt;  &lt;fct&gt;        &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;   &lt;dbl&gt;\n1 0               1      1                1    40 1           0\n2 0               0      0                0    25 1           0\n3 0               1      1                1    28 0           0\n4 0               1      0                1    27 0           0\n5 0               1      1                1    24 0           0\n6 0               1      1                1    25 1           0\n# ℹ 15 more variables: HeartDiseaseorAttack &lt;dbl&gt;, PhysActivity &lt;fct&gt;,\n#   Fruits &lt;fct&gt;, Veggies &lt;fct&gt;, HvyAlcoholConsump &lt;dbl&gt;, AnyHealthcare &lt;dbl&gt;,\n#   NoDocbcCost &lt;dbl&gt;, GenHlth &lt;dbl&gt;, MentHlth &lt;dbl&gt;, PhysHlth &lt;dbl&gt;,\n#   DiffWalk &lt;dbl&gt;, Sex &lt;dbl&gt;, Age &lt;fct&gt;, Education &lt;fct&gt;, Income &lt;dbl&gt;\n\n\nNext, we will update the levels of the factors by renaming them. Therefore, instead of numeric values for the levels the levels will have character values that make more sense.\n\n# Recoding all of the factors\ndata &lt;- data |&gt;\n  select(where(is.factor), BMI) |&gt;\n  mutate(Diabetes_binary = fct_recode(Diabetes_binary,\"No Diabetes\" = \"0\",\n                        \"Diabetes\" = \"1\"),\n         HighBP = fct_recode(HighBP, \"No\" = \"0\",\n                             \"Yes\" = \"1\"),\n         HighChol = fct_recode(HighChol, \"No\" = \"0\",\n                               \"Yes\" = \"1\"),\n         Smoker = fct_recode(Smoker, \"No\" = \"0\",\n                               \"Yes\" = \"1\"),\n         PhysActivity = fct_recode(PhysActivity, \"No\" = \"0\",\n                               \"Yes\" = \"1\"),\n         Fruits = fct_recode(Fruits, \"No\" = \"0\",\n                             \"Yes\" = \"1\"),\n         Veggies = fct_recode(Veggies, \"No\" = \"0\",\n                              \"Yes\" = \"1\"),\n         Age = fct_recode(Age, \n                          \"18-24\" = \"1\",\n                          \"25-29\" = \"2\",\n                          \"30-34\" = \"3\",\n                          \"35-39\" = \"4\",\n                          \"40-44\" = \"5\",\n                          \"45-49\" = \"6\",\n                          \"50-54\" = \"7\",\n                          \"55-59\" = \"8\",\n                          \"60-64\" = \"9\",\n                          \"65-69\" = \"10\",\n                          \"70-74\" = \"11\",\n                          \"75-79\" = \"12\",\n                          \"80+\" = \"13\"),\n         Education = fct_recode(Education,\n                                \"No school\" = \"1\",\n                                \"Grades 1-8\" = \"2\",\n                                \"Grades 9-11\" = \"3\",\n                                \"High School Graduate\" = \"4\",\n                                \"College 1-3 Years\" = \"5\",\n                                \"College Graduate\" = \"6\"))\n\nNext, we will check for missing data in the data set.\n\nsum(is.na(data))\n\n[1] 0\n\n\nAs we can see from this code, there are no missing values in our data set. Therefore, we are able to move forward with our exploratory data analysis without having to think of ways to work around missing values."
  },
  {
    "objectID": "EDA.html#tables",
    "href": "EDA.html#tables",
    "title": "Final Project EDA File",
    "section": "Tables",
    "text": "Tables\n\nAge Group vs. Proportion with Diabetes\nWe will first look at the proportion of people with diabetes across each age group. This will give a better understanding as if age has an impact on the presence of diabetes.\n\nage_proportion_diabetes &lt;- data |&gt;\n  group_by(Age) |&gt;\n  summarize(Proportion_Diabetes = mean(Diabetes_binary == \"Diabetes\")) |&gt;\n  arrange(Age)\nage_proportion_diabetes\n\n# A tibble: 13 × 2\n   Age   Proportion_Diabetes\n   &lt;fct&gt;               &lt;dbl&gt;\n 1 18-24              0.0137\n 2 25-29              0.0184\n 3 30-34              0.0282\n 4 35-39              0.0453\n 5 40-44              0.0650\n 6 45-49              0.0879\n 7 50-54              0.117 \n 8 55-59              0.138 \n 9 60-64              0.172 \n10 65-69              0.204 \n11 70-74              0.218 \n12 75-79              0.213 \n13 80+                0.185 \n\n\nAs we can see from this table, the proportion of people with diabetes in the age group increases as the age group gets older. This shows us that age can be an important factor in regards to predicting diabetes in a subject.\n\n\nEducation Level vs. Proportion with Diabetes\n\neducation_proportion_diabetes &lt;- data |&gt;\n  group_by(Education) |&gt;\n  summarize(Proportion_Diabetes = mean(Diabetes_binary == \"Diabetes\")) |&gt;\n  arrange(Education)\neducation_proportion_diabetes\n\n# A tibble: 6 × 2\n  Education            Proportion_Diabetes\n  &lt;fct&gt;                              &lt;dbl&gt;\n1 No school                         0.270 \n2 Grades 1-8                        0.293 \n3 Grades 9-11                       0.242 \n4 High School Graduate              0.176 \n5 College 1-3 Years                 0.148 \n6 College Graduate                  0.0969\n\n\nAs we can see from this table, the subjects with more education were less likely to have diabetes. There seems to be a negative correlation between these two variables. One possible explanation for this is that the subjects with little to no education most likely come from lower-income families who are not able to afford good healthcare or possibly live in food deserts."
  },
  {
    "objectID": "EDA.html#graphs",
    "href": "EDA.html#graphs",
    "title": "Final Project EDA File",
    "section": "Graphs",
    "text": "Graphs\nNext, we will look at a graph of the proportion of people with diabetes that also have high blood pressure and the proportion of people with diabetes that do not have high blood pressure. This will show if there is a large difference in proportions betweeen these two groups.\n\nGraph of High BP vs. Diabetes\n\n high_BP_Proportion &lt;- data |&gt;\n  group_by(HighBP) |&gt;\n  summarize(Proportion_Diabetes = mean(Diabetes_binary == \"Diabetes\"))\nggplot(high_BP_Proportion, aes(x = HighBP, y = Proportion_Diabetes, fill = HighBP)) +\n  geom_bar(stat = \"identity\", width = 0.7) +\n  scale_y_continuous(labels = percent_format(accuracy = 1)) +\n  labs(\n    title = \"Proportion of Diabetes by BP Status\",\n    x = \"Does Subject Have High BP?\",\n    y = \"Proportion with Diabetes\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nAs we can see, the subjects with High BP are much more likely to have diabetes. Therefore, this variable could be an important predictor variable in our models.\nNow, we will do the same process with the high cholesterol variable, the smoker variable, and the physical activity variable to see if we see similar trends.\n\n\nGraph of High Cholesterol vs. Diabetes\n\nhigh_Chol_Proportion &lt;- data |&gt;\n  group_by(HighChol) |&gt;\n  summarize(Proportion_Diabetes = mean(Diabetes_binary == \"Diabetes\"))\nggplot(high_Chol_Proportion, aes(x = HighChol, y = Proportion_Diabetes, fill = HighChol)) +\n  geom_bar(stat = \"identity\", width = 0.7) +\n  scale_y_continuous(labels = percent_format(accuracy = 1)) +\n  labs(\n    title = \"Proportion of Diabetes by Cholesterol Status\",\n    x = \"Does Subject Have High Cholesterol?\",\n    y = \"Proportion with Diabetes\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nHere, we see a very similar pattern in this graph. This could indicate that cholesterol is important in predicting diabetes, but could also indicate some multicollinearity between our predictors, as someone who has high blood pressure is also likely to have high cholesterol.\n\n\nGraph of Smokers vs. Diabetes\n\nSmokers_Proportion &lt;- data |&gt;\n  group_by(Smoker) |&gt;\n  summarize(Proportion_Diabetes = mean(Diabetes_binary == \"Diabetes\"))\nggplot(Smokers_Proportion, aes(x = Smoker, y = Proportion_Diabetes, fill = Smoker)) +\n  geom_bar(stat = \"identity\", width = 0.7) +\n  scale_y_continuous(labels = percent_format(accuracy = 1)) +\n  labs(\n    title = \"Proportion of Diabetes by Smoker Status\",\n    x = \"Is Subject a Smoker?\",\n    y = \"Proportion with Diabetes\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nIn this graph, we don’t see as much of a gap between proportion of diabetes in the two different groups. This could mean that the binary smoker variable isn’t as important of a predictor to diabetes than high cholesterol or high blood pressure.\n\n\nGraph of Exercise vs. Diabetes\n\nExercise_Proportion &lt;- data |&gt;\n  group_by(PhysActivity) |&gt;\n  summarize(Proportion_Diabetes = mean(Diabetes_binary == \"Diabetes\"))\nggplot(Exercise_Proportion, aes(x = PhysActivity, y = Proportion_Diabetes, fill = PhysActivity)) +\n  geom_bar(stat = \"identity\", width = 0.7) +\n  scale_y_continuous(labels = percent_format(accuracy = 1)) +\n  labs(\n    title = \"Proportion of Diabetes by Exercise Status\",\n    x = \"Does Subject Exercise?\",\n    y = \"Proportion with Diabetes\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nAs we can see from this graph, the subjects that exercise have about a 12% chance of having diabetes, whereas the subjects that do not exercise have about a 22% chance. This predictor could also be valuable in predicting whether or not a subject has diabetes.\nNext, we will make a boxplot of BMI for the group with diabetes and the BMI for the group without diabetes.\n\n\nBoxplots of BMI vs. Diabetes\n\nggplot(data, aes(x=Diabetes_binary, y=BMI, fill = Diabetes_binary)) +\n  geom_boxplot() +\n  labs(\n    title = \"Boxplot Plot of BMI by Diabetes\",\n    x = \"Diabetes\",\n    y = \"BMI\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nThe middle 50% of BMI in the group with diabetes seems to be higher than the middle 50% BMI for the group with no diabetes. Therefore, we would expect a higher BMI to lead to a slightly higher chance of diabetes in the subject."
  }
]