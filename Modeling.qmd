---
title: "ST558FinalModeling"
author: "Luke Freudenheim"
format: html
---


# Introduction

```{r}
library(tidyverse)
library(caret)
library(forcats)
library(scales)
library(ModelMetrics)
```


In this file, we will attempt to find the best statistical model to predict the presence/absence of diabetes in a subject. We will first split the data into a training set and testing set. The training set will be the set of data that the models are trained on. The testing set will be the set of data the models will make predictions about. We will compare the different models with respect to accuracy in predicting the response variable in the test set. The three different types of models we will fit are logistic regression models, classification tree models, and random forest models. In each logistic regression model, we will use a different set of predictors, and compare the sets of predictors with each other to find the most accurate model. In the classification tree and random forest models, we will use the set of predictors that performed best in logistic regression and then use cross validation to find the best tuning parameters to use in the model.

## Reading in and Shaping Data

```{r}
data <- read_csv("diabetes_binary_health_indicators_BRFSS2015.csv")
data <- data |>
  mutate(Diabetes_binary = as.factor(Diabetes_binary),
         HighBP = as.factor(HighBP),
         HighChol = as.factor(HighChol),
         Smoker = as.factor(Smoker),
         Age = as.factor(Age),
         Education = as.factor(Education),
         PhysActivity = as.factor(PhysActivity),
         Fruits = as.factor(Fruits),
         Veggies = as.factor(Veggies)
  )
data <- data |>
  select(where(is.factor), BMI) |>
  mutate(Diabetes_binary = fct_recode(Diabetes_binary,"NoDiabetes" = "0",
                        "Diabetes" = "1"),
         HighBP = fct_recode(HighBP, "No" = "0",
                             "Yes" = "1"),
         HighChol = fct_recode(HighChol, "No" = "0",
                               "Yes" = "1"),
         Smoker = fct_recode(Smoker, "No" = "0",
                               "Yes" = "1"),
         PhysActivity = fct_recode(PhysActivity, "No" = "0",
                               "Yes" = "1"),
         Fruits = fct_recode(Fruits, "No" = "0",
                             "Yes" = "1"),
         Veggies = fct_recode(Veggies, "No" = "0",
                              "Yes" = "1"),
         Age = fct_recode(Age, 
                          "18-24" = "1",
                          "25-29" = "2",
                          "30-34" = "3",
                          "35-39" = "4",
                          "40-44" = "5",
                          "45-49" = "6",
                          "50-54" = "7",
                          "55-59" = "8",
                          "60-64" = "9",
                          "65-69" = "10",
                          "70-74" = "11",
                          "75-79" = "12",
                          "80+" = "13"),
         Education = fct_recode(Education,
                                "Noschool" = "1",
                                "Grades 1-8" = "2",
                                "Grades 9-11" = "3",
                                "High School Graduate" = "4",
                                "College 1-3 Years" = "5",
                                "College Graduate" = "6"))
```

## Splitting Data

Here, we will split the data into a training set and a testing set. We will put 70% of the data set into the training set and 30% of the data into the testing set.

```{r}
# Reproducibility
set.seed(98)
#indices to split on
train <- sample(1:nrow(data), size = nrow(data)*0.7)
test <- setdiff(1:nrow(data), train)
#subset
Diabetes_Train <- data[train, ]
Diabetes_Test <- data[test, ]
```

## Describing Log Loss

In our models the metric we will use to compare models is Log Loss. Log Loss is a metric that is used to evaluate how well probabilistic classifiers perform. This metric is sometimes more effective than accuracy because it takes into account how uncertain predictions are. For example, if a prediction from a model is very close between selecting diabetes and not selecting diabetes (say it's 52% likely the subject has diabetes and 48% likely they don't from the model), then if that prediction is incorrect it is penalized less than a predictions that is almost certain one way or the other (say it's 90% likely the subject has diabetes and 10% likely they don't from the model) and is wrong. The lower the value of Log Loss, the better the model is. Accuracy does not have that capability, and only determines whether or not the model correctly predicted the observation. Therefore, we will be using log loss to compare our models.

## Logistic Regression Model

### Description

A logistic regression model is a supervised learning algorithm that is used for a binary response variable. The algorithm models the log-odds of an event happening by transforming the linear combination of predictors into a probability between 0 and 1. We are using it in this case because we have a response variable that has only 2 categories (the subject either has diabetes or they don't have diabetes). One limitation of logistic regression is that there is an assumption of linearity between the predictors and the response variable.

### First Logisitic Regression Model

```{r}
trctrl <- trainControl(method = "repeatedcv", number = 5, classProbs = TRUE, summaryFunction = mnLogLoss)
Logistic_Model_1 <- train(Diabetes_binary ~ HighBP + HighChol + Smoker + Education + BMI + Veggies + Fruits, data = Diabetes_Train, 
                 method = "glm",
                 family = "binomial",
                 trControl=trctrl,
                 metric = "logLoss",
                 preProcess = c("center", "scale"))
Logistic_Model_1
summary(Logistic_Model_1)
```

As we can see from the output, our logLoss for this model is .3468. Looking at the summary, we see that the fruits variable is insignificant. For the next model, we will take this variable out and insert the exercise binary variable.

### Second Logisitic Regression Model (Fruit dropped, Exercise added)

```{r}
Logistic_Model_2 <-train(Diabetes_binary ~ HighBP + HighChol + Smoker + Education + BMI + Veggies + PhysActivity, data = Diabetes_Train, 
                 method = "glm",
                 family = "binomial",
                 trControl=trctrl,
                 metric = "logLoss",
                 preProcess = c("center", "scale"))
Logistic_Model_2
summary(Logistic_Model_2)
```

The logLoss for this model is .3457, which is slightly lower than the .3468 from the previous model, indicating this model is slightly better. In the summary, we see that all of the variables are significant to the model, so we will not remove any of these predictors and will add age as another predictor.

### Third Logistic Regression Model (Age added)

```{r}
Logistic_Model_3 <-train(Diabetes_binary ~ HighBP + HighChol + Smoker + Education + BMI + Veggies + PhysActivity + Age, data = Diabetes_Train, 
                 method = "glm",
                 family = "binomial",
                 trControl=trctrl,
                 metric = "logLoss",
                 preProcess = c("center", "scale"))
Logistic_Model_3
```

In this model with age added as a predictor, we see that the logLoss is .3384. This is lower than the last two models, so this third model is the best in terms of logLoss. Therefore, we will use this model for our prediction of the test set of data.

## Classification Tree Models

### Description

Classification tree models are a form of predictive modeling where the predictor space is split up into different regions. These models are used for classifying which group the response variable is in. There are different predictions within each region in the predictor space. In each of these regions, the prediction made is the most prevalent class of the response variable. One advantage of classification tree models is that they can account for nonlinear trends in data.

```{r}
Class_Tree_Model <- train(Diabetes_binary ~ HighBP + HighChol + Smoker + Education + BMI + Veggies + PhysActivity + Age, data = Diabetes_Train, 
                 method = "rpart",
                 trControl=trctrl,
                 metric = "logLoss",
                 preProcess = c("center", "scale"),
                 tuneGrid = expand.grid(cp = seq(0,0.01, by=0.001)))
Class_Tree_Model
```

In order to minimize logLoss, the best model was with the tuning parameter cp = 0. Therefore, this is the model we will use in our predictions of the test set. We can see the logLoss of this model in the output above.

## Random Forest Models

### Description

Random forest models are a type of regression/classification algorithm. In random forest models, the data is first broken down into random subsets (bootstrap samples). After this, multiple trees are created for each bootstrap sample, and each tree has a different set of predictors within it that are randomly selected. Each of these trees make predictions for the bootstrap samples, and then these predictions are averaged to determine the final predictions of each sample. Some reasons that random forest models are implemented is they are typically good for prediction and they don't allow 1-2 predictors to overpower the model.

```{r}
Random_Forest_Model <- train(Diabetes_binary ~ HighBP + HighChol + Smoker + Education + BMI + Veggies + PhysActivity + Age, data = Diabetes_Train,
                 method = "rf",
                 trControl=trctrl,
                 metric = "logLoss",
                 preProcess = c("center", "scale"),
                 tuneGrid = data.frame(mtry = 6:8), ntree = 100)
Random_Forest_Model
```

For the random forest model, the tuning parameter that was optimal for the model was mtry = 8. We will use this tuning parameter for the predictions of the test set. We can see the logLoss of this model in the output above.

## Predictions and Final Model Selection

### Predictions Using the Logistic Regression Model

First, we will use the best logistic regression model fit in order to make predictions on the response variable in the test set of data. We will make a confusion matrix to look at the accuracy of this model.

```{r}
LR_predictions <- predict(Logistic_Model_3, newdata = Diabetes_Test)
caret::confusionMatrix(data = Diabetes_Test$Diabetes_binary, reference = LR_predictions)
```

The accuracy of the best logistic regression model was 86.32%. Next, we will see how well the classification tree model performs in predicting the presence/absence of diabetes in the test set.

### Classification Tree Model Predictions

```{r}
CT_predictions <- predict(Class_Tree_Model, newdata = Diabetes_Test)
caret::confusionMatrix(data = Diabetes_Test$Diabetes_binary, reference = CT_predictions)
```

The accuracy of the classification tree model was 85.64%. This is slightly lower than the accuracy for the logistic regression model was. Lastly, we will see how accurate the random forest model is in predicting the response variable in the test data.

### Random Forest Model Predictions

```{r}
RF_predictions <- predict(Random_Forest_Model, newdata = Diabetes_Test)
caret::confusionMatrix(data = Diabetes_Test$Diabetes_binary, reference = RF_predictions)
```

The accuracy of the random forest model in predicting the absence/presence of diabetes in the test set was 86.17%. This accuracy was higher than the accuracy from the classification tree model, but lower than the accuracy from the logistic regression model.

## Overall "Best" Model and Discussion of Results

Overall, the best model in terms of accuracy in the predicting of the test set was the logistic regression model. However, the accuracy from this model was 86.32%, which is lower than the No Information Rate of 96.96%. Therefore, saying every subject in the testing set does not have diabetes would actually have more accuracy than these models. Therefore, we would probably need to look into ways to fine tune these models more or add to them before using them.

